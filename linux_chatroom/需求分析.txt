第一个项目是一个Linux，C++聊天室功能：
分为客户端和服务器：

从功能上看：
客户端：主要就是接收
1.客户可以在服务器注册或者注销,客户被ctrl+c打断的时候也应该被服务器知晓
2.注册的客户可以接收其他注册客户的消息，也可以发送消息
3.每个客户的消息都是发送到所有已经注册的并且还保持连接的客户里

服务器：
监听端口，将新连接的客户放入订阅表，如果发生读事件，则广播给所有订阅客户；
如果客户机出现异常，直接关闭这条连接，并将订阅列表更新，广播消息；
如果客户发送的消息是quit，那么将这个客户删除（但是需要客户自己ctrl+C退出）。回显的时候，显示在线客户人数。

主要的技术实现和逻辑的话：
客户：
1.IO多路复用poll,主要是监听两个文件描述符，一个是标准输入stdin，一个是和服务器的连接socketfd。
2.零拷贝
3.处理逻辑是：首先处理和服务器的连接，如果有事件，区分事件是不是POLLRDHUP，如果是说明服务器下线了，直接退出程序，否则接收服务器的信息并显示在标准输出流上；然后处理客户消息，考虑到客户的标准输入流到socketfd都是在内核，而且比较完整，直用零拷贝内存拷贝过去就可以了。

服务器：
1.使用IO多路复用epoll监听文件描述符，如果触发的事件是自己的监听文件描述符，说明是新来的客户在请求连接，为其创建句柄，挂在epoll的内核事件表上，添加进入订阅者列表，然后向所有的订阅者广播这条消息。
2.为了处理服务器的信号，就用了统一事件源的做法，具体地说就是将信号回调函数设置为将信号通过管道流到epoll监听的事件表上。
3。如果是用户文件描述符，查看是不是下线信号。或者客户主动要求下线，若是，从订阅者列表中删除它，然后广播这条消息。
4.如果只是客户发送消息，那么直接广播就可以了。




压力测试：
我自己写了一个压力测试，服务器和客户端都在一台虚拟机上面。测试手段是模拟100个用户发起对服务器的连接，每个客户发10条消息，耗时大约是两秒。一共有1000条消息，都要被广播给所有客户，所以一共是1K*100=10W条消息，在压力测试下面显示所有客户端加起来一共收到10W条消息，所以是抗住了。但是将客户增加到150人的时候，就会出现显著丢包现象。应该收到22.5W条消息，但实际上统计只收到12W左右的消息。

问题的分析：
服务器的主进程负载压力太大了。服务器是单进程处理消息的，每一个客户的消息都要被服务器广播到所有的客户端上，而且是来一条客户消息，服务器广播完之后，才可以执行下一步操作。消息的数量一多，服务器来不及处理，可能最后socket缓冲区不够用了，就会出现大量的丢包现象。

可能的解决办法：
总的来说：拆分任务。
首先，瓶颈在服务器要负责读客户端的信息，还要负责对客户端的广播上。可能的办法是只让服务器主线程负责读客户端的信息，写的话让其他线程处理。比如：服务器维护一个消息队列，里面存储客户发送的消息，主进程的任务就是往里面写消息。一个客户信息类的数据结构，主要是存储这个客户上次读写的消息队列的位置的指针。还有一个线程池，线程维护一个任务队列，队列里面存放客户信息类，线程池的任务就是负责若干个客户消息的广播。线程被唤醒的事件可以选择定时器。一定时间就唤醒线程池的线程，需要用读写锁锁住消息队列，然后复制内容，进行广播。

进度：
还没开始动手写